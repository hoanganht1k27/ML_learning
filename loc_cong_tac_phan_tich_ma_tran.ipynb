{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loc cong tac phan tich ma tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None, learning_rate = 0.5, max_iter = 1000, print_every = 100):\n",
    "        self.Y = Y # represents the utility matrix\n",
    "        self.K = K\n",
    "        self.lam = lam # regularization parameter\n",
    "        self.learning_rate = learning_rate # for gradient descent\n",
    "        self.max_iter = max_iter # maximum number of iterations\n",
    "        self.print_every = print_every # print loss after each a few iters\n",
    "        self.n_users = int(np.max(Y[:, 0])) + 1\n",
    "        self.n_items = int(np.max(Y[:, 1])) + 1\n",
    "        self.n_ratings = Y.shape[0] # number of known ratings\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\n",
    "        self.W = np.random.randn(K, self.n_items) if Winit is None else Winit\n",
    "\n",
    "        self.b = np.random.randn(self.n_items) # items biases\n",
    "        self.d = np.random.randn(self.n_users) # users biases\n",
    "\n",
    "    def loss(self):\n",
    "        L = 0\n",
    "        for i in range(self.n_ratings):\n",
    "            # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\n",
    "\n",
    "            L += 0.5 * (self.X[m].dot(self.W[:, n]) + self.b[m] + self.d[n] - rating) ** 2\n",
    "        \n",
    "        L /= self.n_ratings\n",
    "        # dont ever forget regularization\n",
    "        return L + 0.5 * self.lam * (np.sum(self.X ** 2) + np.sum(self.W ** 2))\n",
    "\n",
    "    def updateXb(self):\n",
    "        for m in range(self.n_items):\n",
    "            # get all users who rated item m and corresponding ratings\n",
    "            ids = np.where(self.Y[:, 1] == m)[0]\n",
    "            users_ids = self.Y[ids, 0].astype(np.int32)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, users_ids], self.d[users_ids]\n",
    "            for i in range(30): # 30 iterations for each sub problem\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.b[m] + dm - ratings\n",
    "                grad_xm = error.dot(Wm.T) / self.n_ratings + self.lam * xm\n",
    "                grad_bm = np.sum(error) / self.n_ratings\n",
    "\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.learning_rate * grad_xm.reshape(-1)\n",
    "                self.b[m] -= self.learning_rate * grad_bm\n",
    "    def updateWd(self):\n",
    "        for n in range(self.n_users):\n",
    "            # get all items rated by user n and corresponding ratings\n",
    "            ids = np.where(self.Y[:, 0] == n)[0]\n",
    "            items_ids = self.Y[ids, 1].astype(np.int32)\n",
    "            # print(items_ids)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            Xn, bn = self.X[items_ids], self.b[items_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                # print(error.shape, wn.shape, Xn.shape, bn.shape)\n",
    "                grad_wn = Xn.T.dot(error) / self.n_ratings + self.lam * wn\n",
    "                grad_dn = np.sum(error) / self.n_ratings\n",
    "\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.learning_rate * grad_wn.reshape(-1)\n",
    "                self.d[n] -= self.learning_rate * grad_dn\n",
    "\n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateWd()\n",
    "            self.updateXb()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y)\n",
    "                print(\"iter = %d, loss = %.4f, RMSE train = %.4f\" % (it + 1, self.loss(), rmse_train))\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        # predict the rating of user u for item i\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]\n",
    "\n",
    "        return max(0, min(5, pred))\n",
    "    \n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2]) ** 2\n",
    "        \n",
    "        RMSE = np.sqrt(SE / n_tests)\n",
    "\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "rate_train = np.array(ratings_base)\n",
    "rate_test = np.array(ratings_test)\n",
    "\n",
    "rate_train[:, :2] -= 1 # since index start from 0\n",
    "rate_test[:, :2] -= 1 # since index start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 5, loss = 185.1903, RMSE train = 0.9433\n",
      "iter = 10, loss = 185.1668, RMSE train = 0.9181\n",
      "iter = 15, loss = 185.1626, RMSE train = 0.9135\n",
      "iter = 20, loss = 185.1613, RMSE train = 0.9121\n",
      "iter = 25, loss = 185.1606, RMSE train = 0.9114\n",
      "iter = 30, loss = 185.1603, RMSE train = 0.9110\n",
      "Matrix Factorization CF, RMSE =  0.9629150922320201\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50, max_iter = 30)\n",
    "rs.fit()\n",
    "\n",
    "RMSE = rs.evaluate_RMSE(rate_test)\n",
    "print(\"Matrix Factorization CF, RMSE = \", RMSE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
